{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2b45ea",
   "metadata": {},
   "source": [
    "# Subjective Evaluation (ver. 2023.03.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1da9283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, mido, pickle, shutil, random\n",
    "import muspy as mu\n",
    "import os, glob, mido\n",
    "import numpy as np\n",
    "from mido import MidiFile\n",
    "import pretty_midi as pr\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from math import log10,floor\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5731e74",
   "metadata": {},
   "source": [
    "## Sample Selection & Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5189176",
   "metadata": {},
   "source": [
    "### Duration Filtering: 10-60s Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74eee0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 7800 midi files: 100%|███████████| 7800/7800 [02:13<00:00, 58.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "1694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "directory='/data/data1/users/astais/Human-Evaluation/Midi Samples/'\n",
    "# Count number of midis in directory\n",
    "mid_num=len([f for f in Path(directory).rglob('*.mid*')])\n",
    "\n",
    "count=0\n",
    "# iterate over files in directory\n",
    "for f in tqdm(Path(directory).rglob('*.mid*'),total=mid_num,\n",
    "              desc=\"Processing \"+str(mid_num)+\" midi files\"):\n",
    "        try:\n",
    "            mid=MidiFile(f)\n",
    "            if(mid.length<10 or mid.length>60):\n",
    "                os.remove(str(f))\n",
    "                count+=1   \n",
    "        except KeyboardInterrupt:\n",
    "            print('Keyboard Interrupt.')\n",
    "            break\n",
    "        except:\n",
    "            print(\"Error happened. File: \"+str(f))\n",
    "\n",
    "print('Done!')\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e49c4",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d34be63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/data1/users/astais/Human-Evaluation/Midi Samples//training-datasets/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                   | 0/450 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Choosing 96 samples for this directory.:   0%|           | 0/96 [00:00<?, ?it/s]\u001b[A\n",
      "Choosing 96 samples for this directory.:  21%|▏| 20/96 [00:00<00:00, 192.79it/s]\u001b[A\n",
      "Choosing 96 samples for this directory.:  42%|▍| 40/96 [00:00<00:00, 191.77it/s]\u001b[A\n",
      "Choosing 96 samples for this directory.:  62%|▋| 60/96 [00:00<00:00, 167.85it/s]\u001b[A\n",
      "Choosing 96 samples for this directory.: 100%|█| 96/96 [00:00<00:00, 187.20it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "directory='/data/data1/users/astais/Human-Evaluation/Midi Samples/'\n",
    "save_dir='/data/data1/users/astais/Human-Evaluation/Midi-Samples-Sampled/'\n",
    "# Count number of midis in directory\n",
    "\n",
    "# all directories for sampling\n",
    "# directories=[directory+'music-transformer/music-transformer_maestro-v3.0.0/',\n",
    "#              directory+'music-transformer/music-transformer_GiantMIDI-Piano/',\n",
    "#             directory+'music-transformer/music-transformer_ailabs1k7/',\n",
    "#             directory+'music-transformer/music-transformer_Rock-Piano-MIDI-Dataset/',\n",
    "#             directory+'music-transformer/music-transformer_adl-piano-midi/',\n",
    "#              directory+'music-transformer/music-transformer_Los-Angeles-MIDI-Dataset-segment/',\n",
    "#              directory+'perceiver-ar/perceiver-ar_maestro-v3.0.0/',\n",
    "#              directory+'perceiver-ar/perceiver-ar_GiantMIDI-Piano/',\n",
    "# directories=[\n",
    "#             directory+'perceiver-ar/perceiver-ar_ailabs1k7/',\n",
    "#             directory+'perceiver-ar/perceiver-ar_Rock-Piano-MIDI-Dataset/',\n",
    "#             directory+'perceiver-ar/perceiver-ar_adl-piano-midi/',\n",
    "#              directory+'perceiver-ar/perceiver-ar_Los-Angeles-MIDI-Dataset-segment/'\n",
    "#             ]\n",
    "\n",
    "directories=[directory+'/training-datasets/']\n",
    "num=96\n",
    "for Dir in tqdm(directories): \n",
    "    print(Dir)\n",
    "    # count number of midis in directory\n",
    "    mid_num=len(tqdm([f for f in Path(Dir).rglob('*.mid*')]))\n",
    "    file_list = list(Path(Dir).glob(f\"**/*.mid*\"))\n",
    "    if not len(file_list):\n",
    "        print(\"No files found.\")\n",
    "\n",
    "    # iterate over files in directory and randomly copy \n",
    "    for i in tqdm(range(num),desc=\"Choosing \"+str(num)+\" samples for this directory.\"):\n",
    "        while True: \n",
    "            try:\n",
    "                # pick a random file from the file list\n",
    "                rand = random.randint(0, len(file_list) - 1)\n",
    "                file=str(file_list[rand])\n",
    "                \n",
    "                # test that the file can be processed\n",
    "                pr.PrettyMIDI(file)\n",
    "                mu.from_mido(MidiFile(file), duplicate_note_mode='fifo')\n",
    "                # copy file to primers folder\n",
    "                shutil.copy(file,save_dir)\n",
    "            except:            \n",
    "                # Error happened, continue\n",
    "                print(\"Error happened. File: \"+file)\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0037c584",
   "metadata": {},
   "source": [
    "## Listening Test Page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de48a8c",
   "metadata": {},
   "source": [
    "### Create basic and pro users rating dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d011c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic={}\n",
    "pro={}\n",
    "directory='/home/astais/survey/static/samples/'\n",
    "mp3_num=len([f for f in Path(directory).rglob('*.mp3*')])\n",
    "\n",
    "# iterate over files in directory\n",
    "for f in tqdm(Path(directory).rglob('*.mp3*'),total=mp3_num,\n",
    "              desc=\"Processing \"+str(mp3_num)+\" mp3 files\"):\n",
    "        try:\n",
    "            basic[f.name]=[[],[],[],[],[],[],[],[]]\n",
    "            pro[f.name]=[[],[],[],[],[],[],[],[]]\n",
    "        except KeyboardInterrupt:\n",
    "            print('Keyboard Interrupt.')\n",
    "            break\n",
    "        except:\n",
    "            print(\"Error happened. File: \"+str(f))\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "with open('/home/astais/survey/static/ratings/basic.pkl', 'wb') as f:\n",
    "    pickle.dump(basic, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('/home/astais/survey/static/ratings/pro.pkl', 'wb') as f:\n",
    "    pickle.dump(pro, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('/home/astais/survey/static/ratings/basic.pkl', 'rb') as f:\n",
    "    x=pickle.load(f)\n",
    "    \n",
    "with open('/home/astais/survey/static/ratings/pro.pkl', 'rb') as f:\n",
    "    y=pickle.load(f)\n",
    "    \n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5989d2",
   "metadata": {},
   "source": [
    "### Read Rating Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f477dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('/home/astais/survey/static/samples/')\n",
    "print(files)\n",
    "\n",
    "with open('/home/astais/survey/static/samples-list.pkl', 'wb') as f:\n",
    "    pickle.dump(files, f)\n",
    "    \n",
    "with open('/home/astais/survey/static/samples-list.pkl', 'rb') as f:\n",
    "    z=pickle.load(f)\n",
    "    \n",
    "print(z)\n",
    "print(files==z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7349bc6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672\n",
      "672\n"
     ]
    }
   ],
   "source": [
    "with open('/home/astais/survey/static/ratings/ratings_pro.pkl', 'rb') as f:\n",
    "    y=pickle.load(f)\n",
    "with open('/home/astais/survey/static/ratings/ratings_basic.pkl', 'rb') as f:\n",
    "    z=pickle.load(f)\n",
    "print(len(y))\n",
    "print(len(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49548f57",
   "metadata": {},
   "source": [
    "## Subjective Metrics Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6145be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           Sample Name  \\\n",
      "0       music-transformer_GiantMIDI-Piano_Los-Angeles-MIDI-Dataset-segment_97_20230106   \n",
      "1                               music-transformer_maestro-v3.0.0_ailabs1k7_71_20230104   \n",
      "2                               music-transformer_maestro-v3.0.0_ailabs1k7_71_20230104   \n",
      "3                               music-transformer_adl-piano-midi_ailabs1k7_81_20230106   \n",
      "4                               music-transformer_adl-piano-midi_ailabs1k7_81_20230106   \n",
      "...                                                                                ...   \n",
      "1375  perceiver-ar_Los-Angeles-MIDI-Dataset-segment_GiantMIDI-Piano_40_20221207_161342   \n",
      "1376                     perceiver-ar_maestro-v3.0.0_adl-piano-midi_22_20221201_032308   \n",
      "1377                     perceiver-ar_maestro-v3.0.0_adl-piano-midi_22_20221201_032308   \n",
      "1378                             music-transformer_ailabs1k7_maestro-v3.0.0_4_20230106   \n",
      "1379                       music-transformer_adl-piano-midi_maestro-v3.0.0_69_20230106   \n",
      "\n",
      "                   Dataset Type                             Dataset  \\\n",
      "0     Music Transformer Outputs                     GiantMIDI-Piano   \n",
      "1     Music Transformer Outputs                      maestro-v3.0.0   \n",
      "2     Music Transformer Outputs                      maestro-v3.0.0   \n",
      "3     Music Transformer Outputs                      adl-piano-midi   \n",
      "4     Music Transformer Outputs                      adl-piano-midi   \n",
      "...                         ...                                 ...   \n",
      "1375       Perceiver-AR Outputs  Los-Angeles-MIDI-\\nDataset-segment   \n",
      "1376       Perceiver-AR Outputs                      maestro-v3.0.0   \n",
      "1377       Perceiver-AR Outputs                      maestro-v3.0.0   \n",
      "1378  Music Transformer Outputs                           ailabs1k7   \n",
      "1379  Music Transformer Outputs                      adl-piano-midi   \n",
      "\n",
      "                          Primer Dataset Musical Knowledge  Familiarity  \\\n",
      "0     Los-Angeles-MIDI-\\nDataset-segment             Basic            2   \n",
      "1                              ailabs1k7             Basic            1   \n",
      "2                              ailabs1k7             Basic            3   \n",
      "3                              ailabs1k7             Basic            2   \n",
      "4                              ailabs1k7             Basic            2   \n",
      "...                                  ...               ...          ...   \n",
      "1375                     GiantMIDI-Piano               Pro            0   \n",
      "1376                      adl-piano-midi               Pro            0   \n",
      "1377                      adl-piano-midi               Pro            0   \n",
      "1378                      maestro-v3.0.0               Pro            0   \n",
      "1379                      maestro-v3.0.0               Pro            0   \n",
      "\n",
      "      Emotion  Melodiousness  Harmonicity  Rhythmicity  Genre  Naturalness  \\\n",
      "0           2              0            0            0      0            1   \n",
      "1           3              0            0            0      0            2   \n",
      "2           2              0            0            0      0            1   \n",
      "3           1              0            0            0      0            1   \n",
      "4           2              0            0            0      0            1   \n",
      "...       ...            ...          ...          ...    ...          ...   \n",
      "1375        3              2            2            3      2            1   \n",
      "1376        5              4            5            4      3            2   \n",
      "1377        3              4            3            3      2            1   \n",
      "1378        3              3            2            4      2            1   \n",
      "1379        2              1            2            1      2            1   \n",
      "\n",
      "      Rating  \n",
      "0          3  \n",
      "1          3  \n",
      "2          3  \n",
      "3          1  \n",
      "4          1  \n",
      "...      ...  \n",
      "1375       2  \n",
      "1376       4  \n",
      "1377       3  \n",
      "1378       2  \n",
      "1379       1  \n",
      "\n",
      "[1380 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "d_n={\n",
    "    'ratings_basic.pkl':\"Basic\",\n",
    "    'ratings_pro.pkl':\"Pro\",\n",
    "    \"music-transformer\": \"Music Transformer Outputs\",\n",
    "    \"perceiver-ar\": \"Perceiver-AR Outputs\",\n",
    "    \"training-datasets\": \"Training Dataset\",\n",
    "    \"adl-piano-midi\": \"adl-piano-midi\" , \n",
    "    \"ailabs1k7\": \"ailabs1k7\",\n",
    "    \"ailabs1k17\": \"ailabs1k7\",\n",
    "    \"GiantMIDI-Piano\": \"GiantMIDI-Piano\",\n",
    "    \"Los-Angeles-MIDI-Dataset-segment\": \"Los-Angeles-MIDI-\\nDataset-segment\", \n",
    "    \"maestro-v3.0.0\": \"maestro-v3.0.0\",\n",
    "    \"Rock-Piano-MIDI-Dataset\": \"Rock-Piano-\\nMIDI-Dataset\"\n",
    "}\n",
    "\n",
    "\n",
    "# create lists to store the values\n",
    "sample_names = []\n",
    "dataset_types = []\n",
    "datasets = []\n",
    "primer_datasets=[]\n",
    "users=[]\n",
    "similar_music = []\n",
    "emotions = []\n",
    "melody = []\n",
    "harmony = []\n",
    "rhythm = []\n",
    "genre = []\n",
    "creator = []\n",
    "rating = []\n",
    "\n",
    "for file in ['ratings_basic.pkl','ratings_pro.pkl']:\n",
    "    \n",
    "    # load the dictionary\n",
    "    with open('/home/astais/'+file, 'rb') as f:\n",
    "        ratings_dict = pickle.load(f)\n",
    "    \n",
    "    # iterate over the dictionary and extract the values\n",
    "    for sample, ratings in ratings_dict.items():\n",
    "        sample_name = sample.split(\"_no-primer\")[0]\n",
    "        dataset_type = d_n[sample.split(\"_\")[0]]\n",
    "        dataset = d_n[sample.split(\"_\")[1]]\n",
    "\n",
    "        if(dataset_type==\"Training Dataset\"):\n",
    "            primer_dataset=dataset\n",
    "        else:\n",
    "            primer_dataset = d_n[sample.split(\"_\")[2]]\n",
    "\n",
    "        # If the sample has no ratings, skip\n",
    "        if (ratings==[[], [], [], [], [], [], [], []]):\n",
    "            continue\n",
    "\n",
    "        for i in range(len(ratings[0])):\n",
    "            sample_names.append(sample_name)\n",
    "            dataset_types.append(dataset_type)\n",
    "            datasets.append(dataset)\n",
    "            primer_datasets.append(primer_dataset)\n",
    "            users.append(d_n[file])\n",
    "            similar_music.append(ratings[0][i])\n",
    "            emotions.append(ratings[1][i])\n",
    "            melody.append(ratings[2][i])\n",
    "            harmony.append(ratings[3][i])\n",
    "            rhythm.append(ratings[4][i])\n",
    "            genre.append(ratings[5][i])\n",
    "            creator.append(ratings[6][i])\n",
    "            rating.append(ratings[7][i])\n",
    "\n",
    "\n",
    "# create the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Sample Name\": sample_names,\n",
    "    \"Dataset Type\": dataset_types,\n",
    "    \"Dataset\": datasets,\n",
    "    \"Primer Dataset\": primer_datasets,\n",
    "    \"Musical Knowledge\": users,\n",
    "    \"Familiarity\": similar_music,\n",
    "    \"Emotion\": emotions,\n",
    "    \"Melodiousness\": melody,\n",
    "    \"Harmonicity\": harmony,\n",
    "    \"Rhythmicity\": rhythm,\n",
    "    \"Genre\": genre,\n",
    "    \"Naturalness\": creator,\n",
    "    \"Rating\": rating\n",
    "})\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df)\n",
    "\n",
    "# Save dataframe to pickle file\n",
    "df.to_pickle('/home/astais/ratings_dataframe.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386a8e1",
   "metadata": {},
   "source": [
    "### Subjective Metrics Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "714ed38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Dataset Type                           Dataset  \\\n",
      "count           Training Dataset                    adl-piano-midi   \n",
      "mean            Training Dataset                    adl-piano-midi   \n",
      "std             Training Dataset                    adl-piano-midi   \n",
      "count  Music Transformer Outputs                    adl-piano-midi   \n",
      "mean   Music Transformer Outputs                    adl-piano-midi   \n",
      "std    Music Transformer Outputs                    adl-piano-midi   \n",
      "count       Perceiver-AR Outputs                    adl-piano-midi   \n",
      "mean        Perceiver-AR Outputs                    adl-piano-midi   \n",
      "std         Perceiver-AR Outputs                    adl-piano-midi   \n",
      "count           Training Dataset                         ailabs1k7   \n",
      "mean            Training Dataset                         ailabs1k7   \n",
      "std             Training Dataset                         ailabs1k7   \n",
      "count  Music Transformer Outputs                         ailabs1k7   \n",
      "mean   Music Transformer Outputs                         ailabs1k7   \n",
      "std    Music Transformer Outputs                         ailabs1k7   \n",
      "count       Perceiver-AR Outputs                         ailabs1k7   \n",
      "mean        Perceiver-AR Outputs                         ailabs1k7   \n",
      "std         Perceiver-AR Outputs                         ailabs1k7   \n",
      "count           Training Dataset                   GiantMIDI-Piano   \n",
      "mean            Training Dataset                   GiantMIDI-Piano   \n",
      "std             Training Dataset                   GiantMIDI-Piano   \n",
      "count  Music Transformer Outputs                   GiantMIDI-Piano   \n",
      "mean   Music Transformer Outputs                   GiantMIDI-Piano   \n",
      "std    Music Transformer Outputs                   GiantMIDI-Piano   \n",
      "count       Perceiver-AR Outputs                   GiantMIDI-Piano   \n",
      "mean        Perceiver-AR Outputs                   GiantMIDI-Piano   \n",
      "std         Perceiver-AR Outputs                   GiantMIDI-Piano   \n",
      "count           Training Dataset  Los-Angeles-MIDI-Dataset-segment   \n",
      "mean            Training Dataset  Los-Angeles-MIDI-Dataset-segment   \n",
      "std             Training Dataset  Los-Angeles-MIDI-Dataset-segment   \n",
      "count  Music Transformer Outputs  Los-Angeles-MIDI-Dataset-segment   \n",
      "mean   Music Transformer Outputs  Los-Angeles-MIDI-Dataset-segment   \n",
      "std    Music Transformer Outputs  Los-Angeles-MIDI-Dataset-segment   \n",
      "count       Perceiver-AR Outputs  Los-Angeles-MIDI-Dataset-segment   \n",
      "mean        Perceiver-AR Outputs  Los-Angeles-MIDI-Dataset-segment   \n",
      "std         Perceiver-AR Outputs  Los-Angeles-MIDI-Dataset-segment   \n",
      "count           Training Dataset                    maestro-v3.0.0   \n",
      "mean            Training Dataset                    maestro-v3.0.0   \n",
      "std             Training Dataset                    maestro-v3.0.0   \n",
      "count  Music Transformer Outputs                    maestro-v3.0.0   \n",
      "mean   Music Transformer Outputs                    maestro-v3.0.0   \n",
      "std    Music Transformer Outputs                    maestro-v3.0.0   \n",
      "count       Perceiver-AR Outputs                    maestro-v3.0.0   \n",
      "mean        Perceiver-AR Outputs                    maestro-v3.0.0   \n",
      "std         Perceiver-AR Outputs                    maestro-v3.0.0   \n",
      "count           Training Dataset           Rock-Piano-MIDI-Dataset   \n",
      "mean            Training Dataset           Rock-Piano-MIDI-Dataset   \n",
      "std             Training Dataset           Rock-Piano-MIDI-Dataset   \n",
      "count  Music Transformer Outputs           Rock-Piano-MIDI-Dataset   \n",
      "mean   Music Transformer Outputs           Rock-Piano-MIDI-Dataset   \n",
      "std    Music Transformer Outputs           Rock-Piano-MIDI-Dataset   \n",
      "count       Perceiver-AR Outputs           Rock-Piano-MIDI-Dataset   \n",
      "mean        Perceiver-AR Outputs           Rock-Piano-MIDI-Dataset   \n",
      "std         Perceiver-AR Outputs           Rock-Piano-MIDI-Dataset   \n",
      "\n",
      "       Familiarity  Emotion  Naturalness  Rating  \n",
      "count       24.000   24.000       24.000  24.000  \n",
      "mean         3.000    2.792        1.375   2.708  \n",
      "std          1.022    1.021        0.495   0.908  \n",
      "count       47.000   47.000       47.000  47.000  \n",
      "mean         2.787    2.894        1.319   2.745  \n",
      "std          1.215    1.255        0.471   1.188  \n",
      "count       51.000   51.000       51.000  51.000  \n",
      "mean         3.078    3.196        1.471   3.000  \n",
      "std          1.163    1.217        0.504   0.959  \n",
      "count       15.000   15.000       15.000  15.000  \n",
      "mean         3.133    3.200        1.467   3.333  \n",
      "std          0.915    1.014        0.516   1.113  \n",
      "count       49.000   49.000       49.000  49.000  \n",
      "mean         3.163    3.061        1.449   2.959  \n",
      "std          1.280    1.069        0.503   1.136  \n",
      "count       51.000   51.000       51.000  51.000  \n",
      "mean         3.275    3.353        1.490   3.059  \n",
      "std          1.060    1.036        0.505   0.810  \n",
      "count       16.000   16.000       16.000  16.000  \n",
      "mean         3.000    2.562        1.438   2.750  \n",
      "std          1.265    0.892        0.512   1.000  \n",
      "count       50.000   50.000       50.000  50.000  \n",
      "mean         3.240    3.100        1.480   3.120  \n",
      "std          1.041    1.035        0.505   0.961  \n",
      "count       43.000   43.000       43.000  43.000  \n",
      "mean         2.977    3.070        1.442   2.791  \n",
      "std          1.035    1.009        0.502   1.036  \n",
      "count       15.000   15.000       15.000  15.000  \n",
      "mean         3.200    3.000        1.333   2.667  \n",
      "std          1.082    1.134        0.488   1.291  \n",
      "count       45.000   45.000       45.000  45.000  \n",
      "mean         3.156    3.089        1.467   3.044  \n",
      "std          1.147    1.240        0.505   1.086  \n",
      "count       46.000   46.000       46.000  46.000  \n",
      "mean         2.891    2.891        1.370   2.761  \n",
      "std          1.251    1.178        0.488   1.058  \n",
      "count       13.000   13.000       13.000  13.000  \n",
      "mean         3.308    2.923        1.538   2.923  \n",
      "std          1.251    1.441        0.519   1.382  \n",
      "count       50.000   50.000       50.000  50.000  \n",
      "mean         2.900    2.800        1.480   2.900  \n",
      "std          1.165    1.088        0.505   1.093  \n",
      "count       46.000   46.000       46.000  46.000  \n",
      "mean         2.848    2.848        1.304   2.674  \n",
      "std          1.010    0.868        0.465   0.871  \n",
      "count       14.000   14.000       14.000  14.000  \n",
      "mean         3.286    3.000        1.500   3.143  \n",
      "std          1.069    1.359        0.519   0.949  \n",
      "count       43.000   43.000       43.000  43.000  \n",
      "mean         3.140    3.140        1.395   2.860  \n",
      "std          0.966    1.014        0.495   1.060  \n",
      "count       56.000   56.000       56.000  56.000  \n",
      "mean         3.036    3.000        1.393   3.036  \n",
      "std          1.159    1.062        0.493   1.095  \n",
      "                    Dataset Type                           Dataset  Emotion  \\\n",
      "count           Training Dataset                    adl-piano-midi   13.000   \n",
      "mean            Training Dataset                    adl-piano-midi    3.077   \n",
      "std             Training Dataset                    adl-piano-midi    1.256   \n",
      "count  Music Transformer Outputs                    adl-piano-midi   41.000   \n",
      "mean   Music Transformer Outputs                    adl-piano-midi    3.244   \n",
      "std    Music Transformer Outputs                    adl-piano-midi    1.220   \n",
      "count       Perceiver-AR Outputs                    adl-piano-midi   56.000   \n",
      "mean        Perceiver-AR Outputs                    adl-piano-midi    3.375   \n",
      "std         Perceiver-AR Outputs                    adl-piano-midi    1.287   \n",
      "count           Training Dataset                         ailabs1k7   24.000   \n",
      "mean            Training Dataset                         ailabs1k7    3.875   \n",
      "std             Training Dataset                         ailabs1k7    1.035   \n",
      "count  Music Transformer Outputs                         ailabs1k7   48.000   \n",
      "mean   Music Transformer Outputs                         ailabs1k7    3.396   \n",
      "std    Music Transformer Outputs                         ailabs1k7    1.144   \n",
      "count       Perceiver-AR Outputs                         ailabs1k7   53.000   \n",
      "mean        Perceiver-AR Outputs                         ailabs1k7    3.283   \n",
      "std         Perceiver-AR Outputs                         ailabs1k7    1.292   \n",
      "count           Training Dataset                   GiantMIDI-Piano   13.000   \n",
      "mean            Training Dataset                   GiantMIDI-Piano    3.692   \n",
      "std             Training Dataset                   GiantMIDI-Piano    0.855   \n",
      "count  Music Transformer Outputs                   GiantMIDI-Piano   55.000   \n",
      "mean   Music Transformer Outputs                   GiantMIDI-Piano    3.073   \n",
      "std    Music Transformer Outputs                   GiantMIDI-Piano    1.136   \n",
      "count       Perceiver-AR Outputs                   GiantMIDI-Piano   51.000   \n",
      "mean        Perceiver-AR Outputs                   GiantMIDI-Piano    3.176   \n",
      "std         Perceiver-AR Outputs                   GiantMIDI-Piano    1.212   \n",
      "count           Training Dataset  Los-Angeles-MIDI-Dataset-segment   22.000   \n",
      "mean            Training Dataset  Los-Angeles-MIDI-Dataset-segment    3.045   \n",
      "std             Training Dataset  Los-Angeles-MIDI-Dataset-segment    1.214   \n",
      "count  Music Transformer Outputs  Los-Angeles-MIDI-Dataset-segment   44.000   \n",
      "mean   Music Transformer Outputs  Los-Angeles-MIDI-Dataset-segment    3.432   \n",
      "std    Music Transformer Outputs  Los-Angeles-MIDI-Dataset-segment    1.208   \n",
      "count       Perceiver-AR Outputs  Los-Angeles-MIDI-Dataset-segment   53.000   \n",
      "mean        Perceiver-AR Outputs  Los-Angeles-MIDI-Dataset-segment    3.453   \n",
      "std         Perceiver-AR Outputs  Los-Angeles-MIDI-Dataset-segment    1.048   \n",
      "count           Training Dataset                    maestro-v3.0.0   20.000   \n",
      "mean            Training Dataset                    maestro-v3.0.0    3.150   \n",
      "std             Training Dataset                    maestro-v3.0.0    1.268   \n",
      "count  Music Transformer Outputs                    maestro-v3.0.0   50.000   \n",
      "mean   Music Transformer Outputs                    maestro-v3.0.0    3.120   \n",
      "std    Music Transformer Outputs                    maestro-v3.0.0    1.023   \n",
      "count       Perceiver-AR Outputs                    maestro-v3.0.0   48.000   \n",
      "mean        Perceiver-AR Outputs                    maestro-v3.0.0    3.333   \n",
      "std         Perceiver-AR Outputs                    maestro-v3.0.0    1.117   \n",
      "count           Training Dataset           Rock-Piano-MIDI-Dataset   14.000   \n",
      "mean            Training Dataset           Rock-Piano-MIDI-Dataset    3.143   \n",
      "std             Training Dataset           Rock-Piano-MIDI-Dataset    1.351   \n",
      "count  Music Transformer Outputs           Rock-Piano-MIDI-Dataset   48.000   \n",
      "mean   Music Transformer Outputs           Rock-Piano-MIDI-Dataset    3.208   \n",
      "std    Music Transformer Outputs           Rock-Piano-MIDI-Dataset    1.051   \n",
      "count       Perceiver-AR Outputs           Rock-Piano-MIDI-Dataset   53.000   \n",
      "mean        Perceiver-AR Outputs           Rock-Piano-MIDI-Dataset    3.528   \n",
      "std         Perceiver-AR Outputs           Rock-Piano-MIDI-Dataset    1.120   \n",
      "\n",
      "       Melodiousness  Harmonicity  Rhythmicity   Genre  Naturalness  Rating  \n",
      "count         13.000       13.000       13.000  13.000       13.000  13.000  \n",
      "mean           2.923        3.154        2.615   3.000        1.385   2.846  \n",
      "std            1.382        1.345        1.193   1.472        0.506   1.345  \n",
      "count         41.000       41.000       41.000  41.000       41.000  41.000  \n",
      "mean           3.098        3.146        3.146   3.000        1.317   3.049  \n",
      "std            1.338        1.276        1.370   1.204        0.471   1.264  \n",
      "count         56.000       56.000       56.000  56.000       56.000  56.000  \n",
      "mean           3.125        3.232        3.054   2.821        1.446   3.143  \n",
      "std            1.363        1.307        1.354   1.336        0.502   1.242  \n",
      "count         24.000       24.000       24.000  24.000       24.000  24.000  \n",
      "mean           3.333        3.417        3.583   3.417        1.417   3.417  \n",
      "std            1.167        1.100        1.213   0.974        0.504   1.213  \n",
      "count         48.000       48.000       48.000  48.000       48.000  48.000  \n",
      "mean           3.167        3.292        3.146   2.896        1.250   3.042  \n",
      "std            1.155        1.288        1.384   1.276        0.438   1.202  \n",
      "count         53.000       53.000       53.000  53.000       53.000  53.000  \n",
      "mean           2.925        3.132        2.943   2.717        1.321   3.000  \n",
      "std            1.342        1.373        1.379   1.306        0.471   1.316  \n",
      "count         13.000       13.000       13.000  13.000       13.000  13.000  \n",
      "mean           3.077        3.615        3.000   2.923        1.462   3.231  \n",
      "std            1.188        1.193        1.291   1.498        0.519   1.013  \n",
      "count         55.000       55.000       55.000  55.000       55.000  55.000  \n",
      "mean           2.818        3.109        2.782   2.964        1.291   2.818  \n",
      "std            1.278        1.197        1.272   1.138        0.458   1.203  \n",
      "count         51.000       51.000       51.000  51.000       51.000  51.000  \n",
      "mean           2.824        3.059        2.961   2.725        1.235   2.902  \n",
      "std            1.322        1.271        1.248   1.150        0.428   1.204  \n",
      "count         22.000       22.000       22.000  22.000       22.000  22.000  \n",
      "mean           2.636        2.500        2.545   2.591        1.318   2.636  \n",
      "std            1.177        1.144        1.262   1.141        0.477   1.255  \n",
      "count         44.000       44.000       44.000  44.000       44.000  44.000  \n",
      "mean           3.045        3.182        3.023   2.682        1.295   3.068  \n",
      "std            1.275        1.317        1.372   1.427        0.462   1.354  \n",
      "count         53.000       53.000       53.000  53.000       53.000  53.000  \n",
      "mean           3.189        3.245        3.189   2.925        1.396   3.057  \n",
      "std            1.144        1.159        1.287   1.238        0.494   1.216  \n",
      "count         20.000       20.000       20.000  20.000       20.000  20.000  \n",
      "mean           3.150        3.150        2.950   2.550        1.350   2.950  \n",
      "std            1.461        1.348        1.468   1.504        0.489   1.395  \n",
      "count         50.000       50.000       50.000  50.000       50.000  50.000  \n",
      "mean           2.740        2.880        2.840   2.940        1.300   2.840  \n",
      "std            1.175        1.154        1.235   1.168        0.463   1.218  \n",
      "count         48.000       48.000       48.000  48.000       48.000  48.000  \n",
      "mean           3.083        3.188        3.125   2.771        1.438   2.979  \n",
      "std            1.318        1.249        1.196   1.134        0.501   1.194  \n",
      "count         14.000       14.000       14.000  14.000       14.000  14.000  \n",
      "mean           3.286        3.357        3.143   3.071        1.286   3.071  \n",
      "std            1.204        1.277        1.460   1.207        0.469   1.269  \n",
      "count         48.000       48.000       48.000  48.000       48.000  48.000  \n",
      "mean           2.896        2.917        2.875   2.938        1.250   2.750  \n",
      "std            1.325        1.164        1.282   1.311        0.438   1.376  \n",
      "count         53.000       53.000       53.000  53.000       53.000  53.000  \n",
      "mean           3.245        3.396        3.189   2.811        1.377   3.170  \n",
      "std            1.254        1.115        1.287   1.302        0.489   1.252  \n"
     ]
    }
   ],
   "source": [
    "d_n2={\n",
    "    \"adl-piano-midi\": \"adl-piano-midi\" , \n",
    "    \"ailabs1k7\": \"ailabs1k7\",\n",
    "    \"ailabs1k17\": \"ailabs1k7\",\n",
    "    \"GiantMIDI-Piano\": \"GiantMIDI-Piano\",\n",
    "    \"Los-Angeles-MIDI-\\nDataset-segment\": \"Los-Angeles-MIDI-Dataset-segment\", \n",
    "    \"maestro-v3.0.0\": \"maestro-v3.0.0\",\n",
    "     \"Rock-Piano-\\nMIDI-Dataset\": \"Rock-Piano-MIDI-Dataset\"\n",
    "}\n",
    "\n",
    "excel_df_basic=pd.DataFrame()\n",
    "excel_df_pro=pd.DataFrame()\n",
    "\n",
    "for dataset in datasets:\n",
    "    df_sub = df[(df[\"Dataset\"] == dataset) & (df[\"Dataset Type\"] == \"Training Dataset\") & (df[\"Musical Knowledge\"] == \"Basic\")].describe()\n",
    "    df_sub2 = df[(df[\"Dataset\"] == dataset) & (df[\"Dataset Type\"] == \"Music Transformer Outputs\") & (df[\"Musical Knowledge\"] == \"Basic\")].describe()\n",
    "    df_sub3 = df[(df[\"Dataset\"] == dataset) & (df[\"Dataset Type\"] == \"Perceiver-AR Outputs\") & (df[\"Musical Knowledge\"] == \"Basic\")].describe()\n",
    "    df_sub4 = df[(df[\"Dataset\"] == dataset) & (df[\"Dataset Type\"] == \"Training Dataset\") & (df[\"Musical Knowledge\"] == \"Pro\")].describe()\n",
    "    df_sub5 = df[(df[\"Dataset\"] == dataset) & (df[\"Dataset Type\"] == \"Music Transformer Outputs\") & (df[\"Musical Knowledge\"] == \"Pro\")].describe()\n",
    "    df_sub6 = df[(df[\"Dataset\"] == dataset) & (df[\"Dataset Type\"] == \"Perceiver-AR Outputs\") & (df[\"Musical Knowledge\"] == \"Pro\")].describe()\n",
    "    \n",
    "    df_sub.insert(loc=0, column='Dataset Type', value=[\"Training Dataset\"] *  len(df_sub))\n",
    "    df_sub.insert(loc=1, column='Dataset', value=[d_n2[dataset]] * len(df_sub))\n",
    "    df_sub2.insert(loc=0, column='Dataset Type', value=[\"Music Transformer Outputs\"] *  len(df_sub2))\n",
    "    df_sub2.insert(loc=1, column='Dataset', value=[d_n2[dataset]] * len(df_sub2))\n",
    "    df_sub3.insert(loc=0, column='Dataset Type', value=[\"Perceiver-AR Outputs\"] *  len(df_sub3))\n",
    "    df_sub3.insert(loc=1, column='Dataset', value=[d_n2[dataset]]* len(df_sub3))\n",
    "    df_sub4.insert(loc=0, column='Dataset Type', value=[\"Training Dataset\"] *  len(df_sub4))\n",
    "    df_sub4.insert(loc=1, column='Dataset', value=[d_n2[dataset]] * len(df_sub4))\n",
    "    df_sub5.insert(loc=0, column='Dataset Type', value=[\"Music Transformer Outputs\"] *  len(df_sub5))    \n",
    "    df_sub5.insert(loc=1, column='Dataset', value=[d_n2[dataset]] * len(df_sub5))\n",
    "    df_sub6.insert(loc=0, column='Dataset Type', value=[\"Perceiver-AR Outputs\"] *  len(df_sub6))\n",
    "    df_sub6.insert(loc=1, column='Dataset', value=[d_n2[dataset]] * len(df_sub6))\n",
    "    \n",
    "    df_sub.drop([\"Melodiousness\",\"Harmonicity\", \"Rhythmicity\",\"Genre\"], inplace=True, axis=1)\n",
    "    df_sub2.drop([\"Melodiousness\",\"Harmonicity\", \"Rhythmicity\",\"Genre\"], inplace=True, axis=1)\n",
    "    df_sub3.drop([\"Melodiousness\",\"Harmonicity\", \"Rhythmicity\",\"Genre\"], inplace=True, axis=1)\n",
    "    df_sub4.drop([\"Familiarity\"], inplace=True, axis=1)\n",
    "    df_sub5.drop([\"Familiarity\"], inplace=True, axis=1)\n",
    "    df_sub6.drop([\"Familiarity\"], inplace=True, axis=1)\n",
    "\n",
    "    df_sub.drop([\"min\",\"25%\", \"50%\",\"75%\",\"max\"], inplace=True, axis=0)\n",
    "    df_sub2.drop([\"min\",\"25%\", \"50%\",\"75%\",\"max\"], inplace=True, axis=0)\n",
    "    df_sub3.drop([\"min\",\"25%\", \"50%\",\"75%\",\"max\"], inplace=True, axis=0)\n",
    "    df_sub4.drop([\"min\",\"25%\", \"50%\",\"75%\",\"max\"], inplace=True, axis=0)\n",
    "    df_sub5.drop([\"min\",\"25%\", \"50%\",\"75%\",\"max\"], inplace=True, axis=0)\n",
    "    df_sub6.drop([\"min\",\"25%\", \"50%\",\"75%\",\"max\"], inplace=True, axis=0)\n",
    "    \n",
    "#     df_sub.to_excel(d_n2[dataset]+\"_Training-Dataset_basic.xlsx\")\n",
    "#     df_sub2.to_excel(d_n2[dataset]+\"_Music Transformer Outputs_basic.xlsx\")\n",
    "#     df_sub3.to_excel(d_n2[dataset]+\"_Perceiver-AR Outputs_basic.xlsx\")\n",
    "#     df_sub4.to_excel(d_n2[dataset]+\"_Training-Dataset_pro.xlsx\")\n",
    "#     df_sub5.to_excel(d_n2[dataset]+\"_Music Transformer Outputs_pro.xlsx\")\n",
    "#     df_sub6.to_excel(d_n2[dataset]+\"_Perceiver-AR Outputs_pro.xlsx\")\n",
    "\n",
    "    excel_df_basic=pd.concat([excel_df_basic,df_sub,df_sub2,df_sub3])\n",
    "    excel_df_pro=pd.concat([excel_df_pro,df_sub4,df_sub5,df_sub6])\n",
    "\n",
    "print(excel_df_basic)\n",
    "print(excel_df_pro)\n",
    "    \n",
    "excel_df_basic.to_excel(\"subjective_metrics_basic.xlsx\")\n",
    "excel_df_pro.to_excel(\"subjective_metrics_pro.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72114163",
   "metadata": {},
   "source": [
    "### Subjective Metrics Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "58bf4eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:04<00:00,  1.57it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:02<00:00,  1.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics=[ \"Familiarity\",\n",
    "    \"Emotion\",\n",
    "    \"Melodiousness\",\n",
    "    \"Harmonicity\",\n",
    "    \"Rhythmicity\",\n",
    "    \"Genre\",\n",
    "    \"Naturalness\",\n",
    "    \"Rating\"]\n",
    "\n",
    "df_pro = df[df[\"Musical Knowledge\"] == \"Pro\"]\n",
    "df_basic = df[df[\"Musical Knowledge\"] == \"Basic\"]\n",
    "# print(df_pro)\n",
    "# print(df_basic)\n",
    "\n",
    "for metric in tqdm([\"Emotion\", \"Melodiousness\", \"Harmonicity\", \"Rhythmicity\", \"Genre\", \"Naturalness\", \"Rating\"]):    \n",
    "    \n",
    "    # Barplot\n",
    "    sns.set(rc={'figure.figsize':(12,8)})\n",
    "    g = sns.barplot(data=df_pro, x=\"Dataset\", y=metric, errorbar='sd', capsize=.1, hue='Dataset Type',hue_order=\n",
    "                    ['Training Dataset','Music Transformer Outputs', 'Perceiver-AR Outputs'])\n",
    "    if(metric==\"Naturalness\"):\n",
    "        g.set(ylim=(1,2))\n",
    "    else:\n",
    "        g.set(ylim=(1,5))\n",
    "    g.set(title =metric+\" Barplot\")\n",
    "    g.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "    g.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "    g.grid(which='minor', alpha=0.3)\n",
    "    g.grid(which='major', alpha=0.6)\n",
    "    g.figure.savefig(metric+\"_barplot_pro.png\",dpi=300)\n",
    "    g.figure.show()\n",
    "    g.figure.clf()\n",
    "    \n",
    "#     # Violin plot\n",
    "#     sns.set(rc={'figure.figsize':(12,8)})\n",
    "#     g = sns.violinplot(data=df_pro, x=\"Dataset\", y=metric, hue='Dataset Type',hue_order=\n",
    "#                     ['Training Dataset','Music Transformer Outputs', 'Perceiver-AR Outputs'])\n",
    "#     g.set(title =metric+\" Violinplot\")\n",
    "#     g.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "#     g.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "#     g.grid(which='minor', alpha=0.3)\n",
    "#     g.grid(which='major', alpha=0.6)\n",
    "    \n",
    "#     g.figure.savefig(metric+\"_violinplot.png\",dpi=300)\n",
    "#     g.figure.show()\n",
    "#     g.figure.clf()\n",
    "\n",
    "for metric in tqdm([\"Familiarity\",\"Emotion\", \"Naturalness\", \"Rating\"]):    \n",
    "    \n",
    "    # Barplot\n",
    "    sns.set(rc={'figure.figsize':(12,8)})\n",
    "    g = sns.barplot(data=df_basic, x=\"Dataset\", y=metric, errorbar='sd', capsize=.1, hue='Dataset Type',hue_order=\n",
    "                    ['Training Dataset','Music Transformer Outputs', 'Perceiver-AR Outputs'])\n",
    "    if(metric==\"Naturalness\"):\n",
    "        g.set(ylim=(1,2))\n",
    "    else:\n",
    "        g.set(ylim=(1,5))\n",
    "    g.set(title =metric+\" Barplot\")\n",
    "    g.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "    g.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "    g.grid(which='minor', alpha=0.3)\n",
    "    g.grid(which='major', alpha=0.6)\n",
    "    g.figure.savefig(metric+\"_barplot_basic.png\",dpi=300)\n",
    "    g.figure.show()\n",
    "    g.figure.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216dc38e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c380be750c5e6af527ceaac80574712fc4605a2605c2f00cf67db89e2a6bf26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
